{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve EU Gesetzt\n",
    "\n",
    "Code explanation in the file 'eu_gesetzt_code_explanation.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ongoing notes:\n",
    "\n",
    "Each law has a total different html structure, so I could not run one single loop to all of them. \n",
    "I'll try to roll te loop with pdf, because the final structure is similar. <br>\n",
    "The first law (Daten Governance Act) is ready  :)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Getting the law: Daten-Governance-Rechtsakt\n",
    "\n",
    "URL = \"https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=CELEX:32022R0868&qid=1666873096926&from=EN\", \n",
    "law = \"Daten-Governance-Rechtsakt\"\n",
    "r = requests.get(URL) \n",
    "soup = BeautifulSoup(r.content, 'html5lib') \n",
    "\n",
    "\n",
    "## Getting all the artikels and separating Artikels with and without Absatze:\n",
    "\n",
    "#1. getting all artikels and absatze:\n",
    "\n",
    "ids = [tag['id'] for tag in soup.select('div[id]')]\n",
    "\n",
    "df = pd.DataFrame(ids)\n",
    "df.rename(columns={list(df)[0]:'ids'}, inplace=True)\n",
    "df['artikel'] = df['ids'].str[:3]\n",
    "df\n",
    "\n",
    "#2. Looking which one of them have Absatze\n",
    "\n",
    "df1 = df.groupby(['artikel']).count().reset_index()\n",
    "df1 = df1.query(\"ids > 1\")\n",
    "ids_mit = df1['artikel']#.astype('str')\n",
    "\n",
    "#3. Getting the final ids, so the ids and ids with absatze dont appear twice:\n",
    "ids_final = set(ids) - set(ids_mit)\n",
    "\n",
    "## Creating the table with all Artikel and Absatze:\n",
    "\n",
    "#1. Creating empty df:\n",
    "df_law = pd.DataFrame(columns = ['gesetzt', 'artikel', 'absatz', 'text'])\n",
    "\n",
    "#2. loop for ids:\n",
    "\n",
    "for id_entry in ids_final:\n",
    "    #pegando tudo:\n",
    "    table = soup.find('div', attrs = {'id':id_entry}) \n",
    "    my_str = table.text\n",
    "    result = unicodedata.normalize('NFKD', my_str)   # removind \\xa0\n",
    "    result = \" \".join(result.split())\n",
    "    #result # lindo, est√° o absatz completo\n",
    "    #agora pegando os artigos e os absatz\n",
    "    #criando um df temporario com os detalhes do artigo:\n",
    "    if len(id_entry) < 4:\n",
    "        df_temp = pd.DataFrame({'gesetzt': [law],\n",
    "                                'artikel': [id_entry.split('.')[0]], \n",
    "                                'absatz' : [\"NA\"],\n",
    "                                'text': [result]})\n",
    "    else:\n",
    "        df_temp = pd.DataFrame({'gesetzt': [law],\n",
    "                                'artikel': [id_entry.split('.')[0]], \n",
    "                                'absatz' : [id_entry.split('.')[1]],\n",
    "                                'text': [result]})\n",
    "    #df_temp.dtypes funciona\n",
    "    df_law = pd.concat([df_law, df_temp])\n",
    "\n",
    "df_law\n",
    "\n",
    "df_law.to_csv(\"df_eu_law.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

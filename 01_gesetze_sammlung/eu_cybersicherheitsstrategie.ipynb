{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EU Cybersicherheitsstrategie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=CELEX:52020JC0018&from=EN\"\n",
    "law = \"EU Cybersicherheitsstrategie\"\n",
    "r = requests.get(URL) \n",
    "soup = BeautifulSoup(r.content, 'html5lib') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also a communication, and its quite similar as the EU Grüne Deal. So every paragraph will be treaten as a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#table[93]   # 93 é o último parágrafo até a tabela comecar\n",
    "             # Todos os parágrafos válidos aparentam estar como \"normal\"\n",
    "             # p \"li Normal\" and p \"li ListParagraph\"\n",
    "\n",
    "table = soup.findAll('p', attrs = {'class':'Normal'})\n",
    "table2 = soup.findAll('p', attrs = {'class':'li Normal'})\n",
    "table3 = soup.findAll('p', attrs = {'class':'li ListParagraph'})\n",
    "\n",
    "# eliminar itens 151 até 94\n",
    "\n",
    "retirar = list(range(151, 93, -1))\n",
    "\n",
    "for i in retirar:\n",
    "    del table[i]\n",
    "\n",
    "#juntando os diferentes tipos de parágrafos:\n",
    "\n",
    "for i in table2:\n",
    "    table.append(i)\n",
    "\n",
    "for i in table3:\n",
    "    table.append(i)\n",
    "\n",
    "df_com = pd.DataFrame(columns = ['original_id','gesetzt', 'artikel', 'absatz', 'text'])\n",
    "\n",
    "for element in table:\n",
    "    text = element.get_text()\n",
    "    text = unicodedata.normalize('NFKD', text)   # removind \\xa0\n",
    "    text = re.sub(\"\\n\", \" \", text)\n",
    "    text = re.sub(\"\\s{1,}\", \" \", text)\n",
    "    df_temp = pd.DataFrame({'original_id' : [\"NA\"],\n",
    "                            'gesetzt': [\"eu_gruene_deal_com\"],\n",
    "                            'artikel': [\"NA\"], \n",
    "                            'absatz' : [\"NA\"],\n",
    "                            'text': [text]})\n",
    "    df_com = pd.concat([df_com, df_temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Salvando:\n",
    "\n",
    "df_com.to_csv(\"eu_cybersicherheitsstrategie.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
